\glsreset{de}
\glsreset{ea}
\chapter{Der Lösungsansatz}
\label{sec:sol}

	Dieses Kapitel beginnt mit einer Einführung in die Evolutionären Algorithmen und stellt daraus ein Beispiel vor, welches im weiteren Verlauf der Arbeit verwendet wird.

	\section{\gls{ea}}
	\label{sec:evol}
	
		Hierbei handelt es sich, wie in \cite{ea-intro} beschrieben, um heuristische Verfahren zur Lösung von Problemen, die andernfalls nicht in polynomialer Zeit gelöst werden können. Dabei orientieren sie sich an den Vorgängen der biologischen Evolution. Die Begründung hierfür wird von John H. Holland \cite{j-h-holland} in prägnanter Weise dargelegt: 
	
		\begin{quote}
			\textit{Lebewesen sind vollendete Problemlöser. In der Vielzahl der Aufgaben, die sie bewältigen, übertreffen sie die besten Computerprogramme bei weitem - zur besonderen Frustration der Programmierer, die Monate oder gar Jahre harter geistiger Arbeit für einen Algorithmus aufwenden, während Organismen ihre Fähigkeiten durch den scheinbar ziellosen Mechanismus der Evolution erwerben.}
		\end{quote}
	
		Dieses Zitat bietet eine grobe Vorstellung vom Wesen und der Herkunft von \gls{ea}. In vielen literarischen Werken zu diesem Thema - beispielsweise \cite{ger-kla-kru-intro, eib-smi-ea} - wird festgehalten, dass verschiedene Kategorien von \gls{ea}s existieren. Allerdings ist die zugrunde liegende Idee hinter all diesen Sorten von Algorithmen die selbe und wird von den Autoren in \cite{eib-smi-ea} wie folgt dargelegt:\\
		Gegeben sei eine Gruppe von Individuen, genannt \textit{Population}, die innerhalb einer Umgebung mit begrenzten Ressourcen lebt. Der Kampf um diese löst eine natürliche Selektion aus und führt so zu einer höheren Fitness der Population - ein Vorgang, der sehr gut unter dem Stichwort \textit{Survival of the Fittest} bekannt ist. Nach diesem Vorbild aus der Natur nehme man
		\begin{itemize}
			\item ein zu lösendes Problem (stellvertretend für die Umgebung), abgebildet durch eine (Fitness-)Funktion, welche maximiert oder minimiert werden soll, sowie
			\item eine Menge an Lösungskandidaten (im Folgenden als Individuen bezeichnet), bestehend aus einem Set von Funktionsparameterlisten.
		\end{itemize}
		Auf diese Individuen wird sodann die Fitnessfunktion angewendet und mit dem Ergebnis in abstrakter Weise jeweils die Fitness der einzelnen Individuen gemessen. Dabei erfolgt die Bewertung abhängig davon, ob minimiert oder maximiert werden soll. Im folgenden Schritt erzeugen verschiedene Variationsoperatoren wie Mutation und/oder Rekombination aus der Ursprungspopulation eine neue Population, für welche wiederum die Fitnessfunktion ausgewertet wird. Auf der Basis der jeweiligen Fitnesswerte werden die korrespondierenden Individuen beider Populationen verglichen und davon dasjenige mit der höheren Fitness in die Population der nächsten Generation übernommen.
	
		Die oben genannten Schritte werden so lange iteriert, bis entweder eine geeignete Lösung gefunden wurde oder eine (vorher definierte) maximale Anzahl an Iterationen erreicht ist. Abbildung \ref{fig:ea-flowchart}. veranschaulicht die Funktionsweise von \gls{ea}s nochmals in Form eines einfachen Flussdiagramms.
	
		\begin{figure}[h]
			\centering
			\includegraphics[width=0.7\linewidth]{ea_flowchart}
			\caption[Genereller Ablauf von \gls{ea}s]{Genereller Ablauf von \gls{ea}s (Nachbildung der Graphik aus \cite[Seite 27]{eib-smi-ea})}
			\label{fig:ea-flowchart}
		\end{figure}
	
		Nachstehend wird in Abschnitt \ref{sec:de} der Algorithmus \textit{Differentielle Evolution} als Beispiel aus den \gls{ea} erläutert und in den weiteren Kontext der vorliegenden Arbeit eingebettet.
	
		\glsreset{de}

	\section{\gls{de}}
	\label{sec:de}

		Die Autoren in \cite{storn-price-de} entwickelten den \gls{de}-Algorithmus mit Hinblick auf die im Anschluss gelisteten Anforderungen\footnote{Diese Anforderungen sind zwar in \cite{storn-price-de} lediglich auf Minimierungsprobleme beschränkt, da solche in der Praxis häufiger vorkommen. Allerdings sind sie auf Maximierungsprobleme ebenso anwendbar.}
		an eine in der Praxis anwendbare Optimierungsmethode:
		\begin{enumerate}
			\item Sie soll mit nicht-differenzierbaren und nicht-linearen 
			Funktionen, welche unter Umständen mehrere (lokale) Maxima/Minima 
			aufweisen, umgehen können.
			\item Falls eine sehr rechenintensive Funktion auftritt, soll die Optimierungsmethode parallelisierbar sein. Es soll also möglich sein, die Berechnungen auf mehrere Prozessorkerne auszulagern.
			\item Weiterhin soll die Optimierungsmethode leicht zu benutzen sein. Im gegebenen Kontext bedeutet dies zum Beispiel, dass sie wenige Kontrollparameter besitzt, die einfach bestimmbar sind.
			\item Außerdem soll sie sich mit steigender Iterationszahl immer 
			näher dem \textbf{globalen} Minimum/Maximum annähern.
		\end{enumerate}
		Zwar ist \gls{de} laut \cite{storn-price-de} darauf ausgerichtet, die oben genannten Bedingungen zu erfüllen, den Wahrheitsgehalt dieser Aussage zu prüfen soll jedoch nicht Aufgabe der hier vorliegenden Arbeit sein. Hier liegt der Fokus primär auf der Anwendung des Algorithmus mit der Annahme, die vorangestellte Aussage sei wahr. 
		
		Die Grundstruktur des \gls{de}-Algorithmus lässt sich aus Abbildung \ref{fig:ea-flowchart} ablesen, jedoch muss für eine detaillierte Beschreibung der Idee hinter \gls{de} zunächst folgendes gegeben sein - Definition nach \cite{storn-price-de}:
		\begin{itemize}
			\item eine zu optimierende Funktion $f(x_{1}, x_{2}, ... , x_{D})$ - die \textit{Fitnessfunktion}
			\item eine Population bestehend aus $N_{p}$ $D$-dimensionalen Vektoren $x_{i, g}$, wobei gilt:
			\begin{itemize}
				\item $N_{p}$ ist die Populationsgröße
				\item $D$ entspricht der Anzahl von Parametern für die Fitnessfunktion
				\item $i \in [0,1,2, ... , N_{p}]$
				\item $g$ stellt die Generation der Population dar
			\end{itemize}
			\item der reelle Mutationsfaktor $F \in (0,2]$
			\item die Crossover-Konstante $C_{r} \in (0,1]$
			\item eine maximale Anzahl an Generationen $G$
		\end{itemize}
		
		Es gibt unterschiedliche Varianten des \gls{de}-Algorithmus, welche gewählt werden können und nach folgendem Schema notiert werden: \textit{\gls{de}/x/y/z} mit den nachstehenden Bedeutungen für x, y und z:
		\begin{itemize}
			\item x gibt an, welcher Vektor der Population bei der Mutationsoperation verändert wird. Dies kann entweder ein zufälliger Vektor sein (\textit{rand}) oder derjenige mit dem niedrigsten/höchsten Ergebnis bei Auswertung mit der Fitnessfunktion (\textit{best}).
			\item y entspricht der Anzahl von Differenzvektoren bei der Mutation (in der Regel 1 oder 2).
			\item mit z wird das Crossover-Schema ausgewählt. Üblicherweise wird \textit{bin} verwendet, aber es existieren - wie in \mbox{\cite[Seiten 93-97]{storn-price-de-book}} dokumentiert - einige weitere Schemata - als Beispiel ist hier \textit{exp} zu nennen. Der Sinn hinter diesen Bezeichnungen wird in Abschnitt \ref{sec:de-crossover} deutlich.
		\end{itemize}
		Nach diesem Muster wird die in \cite[Seite 47]{storn-price-de-book} als \textit{klassischer} DE-Algorithmus benannte Art als \textit{\gls{de}/rand/1/bin} geschrieben.
		
		Sind diese Informationen gegeben, kann \gls{de} ,wie in \cite{storn-price-de} dargestellt, beschrieben werden:
		
		\subsection{Initialisierung}
		\label{sec:de-init}
		
			Zunächst muss die initiale Population ($G = 0$) erzeugt werden - meist durch Füllen der Parametervektoren $x_{i, 0}$ mit Zufallszahlen. Im Bezug auf diese Zufallszahlen sowie alle kommenden wird eine Gleichverteilung angenommen. In manchen Fällen ist eine vorläufige Lösung $x_{nom, 0}$ verfügbar - dann kann die Population durch Addieren zufälliger Abweichungen zu $x_{nom, 0}$ generiert werden. Die nachfolgenden Operationen werden so lange iteriert, bis die vorher festgelegte Anzahl an Generationen $G$ erreicht ist.
			
		\subsection{Mutation}
		\label{sec:de-mutation}
		
			Für alle $x_{i, g}$ werden Mutantenvektoren $v_{i, g+1}$ nach der folgenden Rechenvorschrift gebildet:
			\Large
			\begin{flalign}
				\label{eq:mutation1}
				v_{i, g+1} = x_{r_{1}, g} + F \cdot (x_{r_{2}, g} - x_{r_{3}, g})
			\end{flalign}
			\normalsize
			Hierbei bezeichnen $r_{1}$, $r_{2}$ und $r_{3}$ drei zufällig ausgewählte Indices, welche sowohl voneinander als auch von $i$ unterschiedlich sind.
			
			Anzumerken ist, dass anstelle der Vorschrift \ref{eq:mutation1} auch die nachstehende Gleichung verwendet werden kann:
			\Large
			\begin{flalign}
				\label{eq:mutation2}
				v_{i, g+1} = x_{best, g} + F \cdot (x_{r_{1}, g} - x_{r_{2}, g})
			\end{flalign}
			\normalsize
			Dabei wurde in Gleichung \ref{eq:mutation2} der erste Summand durch den Vektor in der aktuellen Generation g ersetzt, der bei Einsetzen in die Fitnessfunktion den niedrigsten/höchsten Wert liefert. Diese Variante wird für das in Abschnitt \ref{sec:testsetting} erläuterte Testszenario verwendet.
			
			Der zweite Summand in Gleichung \ref{eq:mutation1} kann erweitert werden, um die Diversität unter den Vektoren $x_{i, g+1}$ zu erhöhen:
			\Large
			\begin{flalign}
				\label{eq:mutation3}
				F \cdot ((x_{r_{1}, g} + x_{r_{2}, g}) - (x_{r_{3}, g} + x_{r_{4}, g}))
			\end{flalign}
			\normalsize
			Im Rahmen von Abschnitt \ref{sec:testsetting} sollte jedoch die Version aus den Gleichungen \ref{eq:mutation1} und \ref{eq:mutation2} ausreichend sein.
			
		\subsection{Crossover}
		\label{sec:de-crossover}
		
			Das Ergebnis der Crossover-Operation ist eine neue Population, die im Selektionsvorgang mit der Ursprungspopulation konkurriert, mit den Vektoren $u_{i, g+1}$ und ihren Parametern $u_{j, i, g+1}$ mit $j = 1, 2, ... , D$. 
			
	\section{Die Testumgebung}
	\label{sec:testsetting}
